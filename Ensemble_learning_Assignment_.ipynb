{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC35qf_p9I7s",
        "outputId": "3ef74f67-346a-43cb-a38a-fba337779ac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features:\n",
            "                 Feature  Importance\n",
            "23            worst area    0.139357\n",
            "27  worst concave points    0.132225\n",
            "7    mean concave points    0.107046\n",
            "20          worst radius    0.082848\n",
            "22       worst perimeter    0.080850\n"
          ]
        }
      ],
      "source": [
        "#6)Write a Python program to:Load the Breast Cancer dataset using sklearn.datasets.load_breast_cancer()\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X, y)\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "feature_importance_df = feature_importance_df.sort_values(\n",
        "    by='Importance', ascending=False\n",
        ")\n",
        "\n",
        "print(\"Top 5 Most Important Features:\")\n",
        "print(feature_importance_df.head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7)Write a Python program to:Train a Bagging Classifier using Decision Trees on the Iris dataset\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "\n",
        "bagging = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bagging.fit(X_train, y_train)\n",
        "bagging_pred = bagging.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
        "\n",
        "print(\"Accuracy of Single Decision Tree:\", dt_accuracy)\n",
        "print(\"Accuracy of Bagging Classifier:\", bagging_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPu0-W5t-EwG",
        "outputId": "b743e301-b29f-4a8a-9094-1e90db3a940d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Single Decision Tree: 1.0\n",
            "Accuracy of Bagging Classifier: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8) Write a Python program to:Train a Random Forest Classifier  Tune hyperparameters max_depth and n_estimators using GridSearchCV\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10, 20]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_rf = grid_search.best_estimator_\n",
        "\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "final_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Final Model Accuracy:\", final_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cws8j9D0_x1o",
        "outputId": "d4152769-d9c3-4293-a0aa-e07cd8a9b937"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': None, 'n_estimators': 200}\n",
            "Final Model Accuracy: 0.9707602339181286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9)Write a Python program to:Train a Bagging Regressor and a Random Forest Regressor on the California Housing dataset\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "bagging_reg = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_reg.fit(X_train, y_train)\n",
        "bagging_pred = bagging_reg.predict(X_test)\n",
        "bagging_mse = mean_squared_error(y_test, bagging_pred)\n",
        "\n",
        "rf_reg = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "rf_reg.fit(X_train, y_train)\n",
        "rf_pred = rf_reg.predict(X_test)\n",
        "rf_mse = mean_squared_error(y_test, rf_pred)\n",
        "\n",
        "print(\"Bagging Regressor MSE:\", bagging_mse)\n",
        "print(\"Random Forest Regressor MSE:\", rf_mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXoBLOQfBARb",
        "outputId": "21de3611-6f5d-4773-f3b3-c99cff0e6cbf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor MSE: 0.2568358813508342\n",
            "Random Forest Regressor MSE: 0.25650512920799395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10)You are working as a data scientist at a financial institution to predict loan default. You have access to customer demographic and transaction history data\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=5000,\n",
        "    n_features=20,\n",
        "    n_informative=10,\n",
        "    n_redundant=5,\n",
        "    n_classes=2,\n",
        "    weights=[0.7, 0.3],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 1. Bagging-based model (Random Forest)\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 2. Boosting-based model (Gradient Boosting)\n",
        "gb = GradientBoostingClassifier(\n",
        "    n_estimators=150,\n",
        "    max_depth=3,\n",
        "    learning_rate=0.05,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "rf_auc = cross_val_score(rf, X_train, y_train, cv=cv, scoring='roc_auc')\n",
        "gb_auc = cross_val_score(gb, X_train, y_train, cv=cv, scoring='roc_auc')\n",
        "\n",
        "print(\"Random Forest Mean ROC-AUC:\", rf_auc.mean())\n",
        "print(\"Gradient Boosting Mean ROC-AUC:\", gb_auc.mean())\n",
        "\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = gb.predict(X_test)\n",
        "y_prob = gb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Final Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Final ROC-AUC:\", roc_auc_score(y_test, y_prob))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGAdgxvlB1RP",
        "outputId": "4f340029-96fd-49c3-8336-992365aba164"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Mean ROC-AUC: 0.9732259464021975\n",
            "Gradient Boosting Mean ROC-AUC: 0.966355119936867\n",
            "Final Accuracy: 0.904\n",
            "Final ROC-AUC: 0.9501782660855888\n"
          ]
        }
      ]
    }
  ]
}